\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\title{Concurency and Multithreading\\
       Java concurrency Constructs}
\author{Alexandru Mosoi $<$ami650@few.vu.nl$>$\\
        student number 2000903}

\begin{document}
\maketitle


\section{Counter}

\begin{table}[h!]
  \centering
  \small
  \framebox{
    \begin{tabular}{ r | c | c | c | c | c }
    \# Threads & 1 & 2 & 3 & 4 & 8 \\
    \hline
    Simple & 2000000000 & 1000046618 & 670269482 & 500093260 & 252398649 \\
    Volatile & 2000000000 & 1370615635 & 1375495038 & 1414755523 & 1259676634 \\
    Synchronized & 2000000000 & 2000000000 & 2000000000 & 2000000000 & 2000000000 \\
    \end{tabular}
  }

  \caption{Counter value for variable N and K = 2.000.000.000 on a 4 logical
  cores processor}
  \label{tbl:counter}
\end{table}


Table \ref{tbl:counter} lists value of the counter after it was incremented
\texttt{K / N} times on \texttt{N} different threads, for a total of
\texttt{K} increments. The pseudocode executed by a thread is listed in
figure \ref{fig:counter-pseudocode}.

\begin{figure}[h!]
  \begin{verbatim}
  for (long i = 0; i < K / N; i++) {
    counter.inc();
  }
  \end{verbatim}
  \caption{Counter pseudocode}
  \label{fig:counter-pseudocode}
\end{figure}

\subsection{Simple}
\label{ssec:simple}

\emph{Simple} does not use any synchronization constructs. Java
HotSpot assumes that variable is not shared accros multiple threads and
detects an optimization oportunity. The memory access into the following
pattern:

\begin{verbatim}
read counter into local-counter
increment local-counter K/N times
write local-counter to counter
\end{verbatim}

The last thread to execute \texttt{write local-counter} sets the final
value for shared counter. Since there are \texttt{N} threads and each thread
increments the counter \texttt{K/N} times the final value of the counter
will be at least \texttt{K/N}. The slight difference in the reported value
and the theoretical one is because of lazy runtime optimization of Java HotSpot.
Before the loop is optimized the value might have been incremented separately
by all threads.

\subsection{Volatile}
\emph{Volatile} declares the internal counter as \texttt{volatile}.
This will disable optimizations and the memory access pattern changes to

\begin{verbatim}
repeat
  read counter into local-counter
  increment local-counter 1 time
  write local-counter to counter
\end{verbatim}

However when considering multiple threads, for example \texttt{t1} and
\texttt{t2}, the following \emph{race}\footnote{Both threads read the
same value, increment it and then write it back} is possible because
the incrementation is not atomic:

\begin{verbatim}
t1:read counter into local-counter

t2:read counter into local-counter
t2:increment local-counter 1 time
t2:write local-counter to counter

t1:increment local-counter 1 time
t1:write local-counter to counter
\end{verbatim}

Depending on the scheduling of the threads the final value of the counter can
take any value from 1 to \texttt{K}.

\subsection{Synchronized}

\emph{Synchronized} protects the access to internal counter with
the counter's monitor so no two threads will execute the critical
section simultaneously. The memory access pattern will be:

\begin{verbatim}
t1:in critical section
t1:  read counter into local-counter
t1:  increment local-counter 1 time
t1:  write local-counter to counter

t2:in critical section
t2:  read counter into local-counter
t2:  increment local-counter 1 time
t2:  write local-counter to counter
\end{verbatim}

The final value of the counter will always be equal to \emph{K}. This
implementation of the counter works as expected.


\section{Search}

\begin{table}[h!]
  \centering
  \small
  \framebox{
    \begin{tabular}{ r | c | c | c | c }
    \# Threads & 1 & 2 & 3 & 4 \\
    \hline
    Simple & 50000001 & 75000001 & 83333333 & 87500001 \\
    Volatile & 50000001 & 45654166 & 56228251 & 68703196 \\
    \end{tabular}
  }

  \caption{Number of visited entries for variable N and K = 100.000.000 on a 4 logical
  cores processor. Reported values are averaged over 7 runs.}
  \label{tbl:search}
\end{table}

The table \ref{tbl:search} number of entries visited when searching a value
located at \emph{K / N / 2} in a table with \emph{K} elements using \emph{N}
threads. The value is always found by the first thread after searching half of
the elements assigned to it. The pseudocode executed by a thread is
listed in figure \ref{fig:search-pseudocode}. \texttt{found} is a shared
boolean variable set to \texttt{true} when the target value was
found by any of the threads.

\begin{figure}[h!]
  \begin{verbatim}
  for (i = start; i < end && !found; i++) {                                    
    if (table[i] == value) {                                                   
      found = true;                                                            
      break;                                                                   
    }                                                                          
  }                                                                            
                                                                               
  synchronized (Search.class) {                                                
    visited += visited_elements_in_current_thread;
  }
  \end{verbatim}
  \caption{Search pseudocode}
  \label{fig:search-pseudocode}
\end{figure}


\subsection{Simple}

\emph{Simple} doesn't use any synchronization mechanism. Similar to
subsection \ref{ssec:simple} Java HotSpot optimizes away the
read of \texttt{found} because it implicitly assumes that \texttt{found}
is accessed by only a thread and the flag changes at the end of
the loop. The memory access pattern of \texttt{found} is:

\begin{verbatim}
read found into local_found
if not local_found
  for each element in table slice
    if element == value
      write true in found 
      stop
\end{verbatim}

Assuming that all threads start simultaneously and perfect scheduling, the
number of accessed elements will always be \emph{K - (K / N / 2) + 1}. If
the number of threads is large then the first thread might find \emph{value}
before last threads even start and therefore those threads don't need to
search at all.

\subsection{Volatile}

If the shared flag \texttt{found} is made volatile Java HotSpot cannot
optimize away the read. The memory access pattern of \texttt{found} is:

\begin{verbatim}
for each element in table slice
  read found into local_found
  if local_found
    stop
  if element == value
    write true in found 
    stop
\end{verbatim}

When the value is found all threads stop next time they are scheduled
to run. In theory, assuming perfect scheduling and one thread per physical core,
the number of elements accessed is \texttt{K / 2}. In practice, this number
depends on the scheduling of the threads. For example, for two threads on
two processors, the total number of visited elements is usually lower than
\texttt{K / 2} because the first thread has a head start over the second.

\end{document}
